{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlwings as xw\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import warnings\n",
    "\n",
    "def is_nan(x):\n",
    "    return (x is np.nan or x != x)\n",
    "\n",
    "def df_emp(text):\n",
    "    df_empty = pd.DataFrame(index=text,columns=df_CFO.columns)\n",
    "    return df_empty \n",
    "\n",
    "def convert_index_list(index):\n",
    "    index = pd.DataFrame((index))\n",
    "    index = index.dropna().iloc[:,0].tolist()\n",
    "    return index\n",
    "\n",
    "def train_model():\n",
    "    train_df = inputDF.parse(tabnames[2])\n",
    "    \n",
    "    # X train\n",
    "    input_docs = train_df .iloc[:,0:1]\n",
    "    input_docs = list(input_docs[\"Input TEXT\"])\n",
    "    X_train = np.array(input_docs)\n",
    "    \n",
    "    # y train\n",
    "    output_docs = train_df .iloc[:, 1:2]\n",
    "    output_docs = list(output_docs[\"Output TEXT\"]) \n",
    "    y_train_text = [[i] for i in output_docs]\n",
    "     \n",
    "    mlb = MultiLabelBinarizer()\n",
    "    Y = mlb.fit_transform(y_train_text)\n",
    "    \n",
    "    classifier = Pipeline([\n",
    "        ('vectorizer', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', OneVsRestClassifier(LinearSVC()))])\n",
    "    \n",
    "    classifier.fit(X_train, Y)\n",
    "\n",
    "    return classifier, mlb\n",
    "\n",
    "def suggest_words(new_input): \n",
    "\n",
    "    X_test = np.array(new_input)\n",
    "        \n",
    "    classifier,mlb = train_model()\n",
    "    predicted = classifier.predict(X_test)\n",
    "    all_labels = mlb.inverse_transform(predicted)\n",
    "    \n",
    "    return all_labels\n",
    "\n",
    "def condense_data(text_df, start_row=0, end_row=50, col=0):\n",
    "    no_years = int(len(text_df.columns)/2)                                      # each year has two columns \n",
    "    df_list = list()\n",
    "    df_list_reind, df_list_join, index_list = list(), list(), list()\n",
    "     \n",
    "    df = text_df.iloc[start_row:end_row, col:col+2].set_index(\"Statement_1\")\n",
    "    df_list.append(df)\n",
    "    for i in range(1,no_years): \n",
    "        df = text_df.iloc[start_row:end_row, col+(i*2):col+(i*2+2)].set_index(\"Statement_\"+str(i+1))\n",
    "        df_list.append(df)\n",
    "    \n",
    "    df = df_list[0].reset_index().drop_duplicates(subset=\"Statement_1\", keep='first').set_index(\"Statement_1\")\n",
    "    df_list_reind.append(df)\n",
    "    for i in range(1,no_years): \n",
    "        df = df_list[i].reset_index().drop_duplicates(subset=\"Statement_\"+str(i+1), keep='first').set_index(\"Statement_\"+str(i+1))\n",
    "        df_list_reind.append(df)\n",
    "    \n",
    "    df_list_join = df_list_reind[0].join(df_list_reind[1], how='outer')\n",
    "    index_list   = df_list_reind[0].index.union(df_list_reind[1].index)\n",
    "    for i in range(1,no_years-1): \n",
    "        df_list_join = df_list_join.join(df_list_reind[i+1], how='outer')\n",
    "        index_list = index_list.union(df_list_reind[i+1].index)\n",
    "    \n",
    "    df_list_join = df_list_join.reset_index().drop_duplicates(subset='index', keep='first').set_index('index')\n",
    "    df = df_list_join.reindex(index_list)\n",
    "    \n",
    "    # give the new places\n",
    "    df_index = convert_index_list(df.index)\n",
    "    new_df_index = suggest_words(df_index)\n",
    "    \n",
    "    new_df_index= pd.DataFrame(new_df_index).iloc[0:(df.shape[0]),:]\n",
    "    new_df_index.columns = ['Suggestion']\n",
    "    orig_df_index = pd.DataFrame(df_index).iloc[0:(df.shape[0]),:]\n",
    "    orig_df_index.columns = ['Orig']\n",
    "    \n",
    "    label_col = pd.concat([orig_df_index,new_df_index], axis=1)\n",
    "    label_col = label_col.set_index(label_col.columns[0])\n",
    "    \n",
    "    df = pd.concat([df, label_col], axis=1)\n",
    "    df = df.reindex(index_list)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def insert_suggestion(df_full):\n",
    "    dupl_df_list = pd.DataFrame()                                               # initialisation for the store of combined df\n",
    "    index_dupl = list()\n",
    "    \n",
    "    df_fill = df_full.set_index('Suggestion')\n",
    "    dupl_list = df_fill.index[df_fill.index.duplicated()].unique()\n",
    "    \n",
    "    for dupl in dupl_list:\n",
    "        try:                                                                    # try statement to allow if it fails                \n",
    "            if is_nan(dupl) is True or dupl == '-' or dupl== None:\n",
    "                pass\n",
    "                \n",
    "            else:\n",
    "                index_dupl.append(dupl)\n",
    "                dupl_df = df_fill.loc[dupl,:]\n",
    "                dupl_df = dupl_df.apply(pd.to_numeric, errors='ignore')\n",
    "                dupl_df = dupl_df.groupby(dupl_df.index).sum().reset_index()    # groups by similar index\n",
    "                dupl_df.index = [dupl]\n",
    "                dupl_df_list = pd.concat([dupl_df_list, dupl_df], axis=0)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    df_dummy = df_full.reset_index().set_index('Suggestion')                    # create a dummy with the 'Suggestions' as the index\n",
    "    df_dummy = df_dummy.drop(index_dupl).set_index('index')\n",
    "    df_new = pd.concat([df_dummy, dupl_df_list], axis=0)\n",
    "\n",
    "    return df_new \n",
    "\n",
    "def process_df(df_samp, start_row, end_row, replace= \"Yes\"):\n",
    "    df_samp = condense_data(df_samp,start_row,end_row)\n",
    "    \n",
    "    if replace ==\"Yes\":\n",
    "        try:\n",
    "            df_samp = insert_suggestion(df_samp)\n",
    "        except:\n",
    "            print(\"Couldn't rearrange\") \n",
    "        \n",
    "    df_samp = df_samp.fillna(0)\n",
    "\n",
    "    return df_samp\n",
    "\n",
    "# extract data\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "inputDF = pd.ExcelFile('Financials.xlsx')\n",
    "tabnames = inputDF.sheet_names\n",
    "text_df = inputDF.parse(tabnames[1])\n",
    "\n",
    "# open input excel\n",
    "input_wb = xw.Book('Financials.xlsx')\n",
    "input_sht = input_wb.sheets[1]\n",
    "ctrl_sht = input_wb.sheets[0]\n",
    "\n",
    "ML_enable = ctrl_sht.range('E3').value\n",
    "\n",
    "# create the df\n",
    "df_CFO = process_df(text_df,1,100, ML_enable)\n",
    "df_CFI = process_df(text_df,100,200, ML_enable)\n",
    "df_CFF = process_df(text_df,200,300, ML_enable)\n",
    "df_empty = pd.DataFrame(index=['nan'],columns=df_CFO.columns)\n",
    "df_full = pd.concat([df_emp([input_sht.range('A2').value]), df_CFO, df_emp([' ',input_sht.range('A102').value]), df_CFI, df_emp([' ',input_sht.range('A202').value]), df_CFF], axis=0)\n",
    "\n",
    "# take the control input\n",
    "periods = int(ctrl_sht.range('A22').value)\n",
    "df_suggest = df_full['Suggestion']\n",
    "df_full = df_full.iloc[:, 0:periods]\n",
    "\n",
    "# df range manipulation\n",
    "if ctrl_sht.range('E8').value ==\"Yes\":\n",
    "    cols = list(df_full.columns)\n",
    "    try: \n",
    "        cols = list(cols.reverse())\n",
    "    except:\n",
    "        pass\n",
    "    df_full = df_full[cols]\n",
    "    \n",
    "df_full = pd.concat([df_full,df_suggest], axis=1)      \n",
    "\n",
    "# open output excel\n",
    "wb = xw.Book('Output_Financials.xlsx')\n",
    "sht = wb.sheets[0]\n",
    "\n",
    "sht.range('A1').value = pd.DataFrame(index=np.full(1000, np.nan), columns=np.full(30, np.nan))\n",
    "sht.range('A1').value = df_full\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
